---
title: "Random Forest Challenge"
subtitle: "The Power of Weak Learners"
format:
  html: default
execute:
  echo: false
  eval: true
---

# üå≤ Random Forest Challenge - The Power of Weak Learners

::: {.callout-important}
## üìä Challenge Requirements In [Student Analysis Section](#student-analysis-section)

Navigate to the [Student Analysis Section](#student-analysis-section) to see the challenge requirements.

:::

::: {.callout-important}
## üéØ Note on Python Usage

You have not been coached through setting up a Python environment.  **If using Python** You will need to set up a Python environment and install the necessary packages to run this code - takes about 15 minutes; see [https://quarto.org/docs/projects/virtual-environments.html](https://quarto.org/docs/projects/virtual-environments.html).  Alternatively, delete the Python code and only leave the remaining R code that is provided.  You can see the executed Python output at my GitHub pages site: [https://flyaflya.github.io/randomForestChallenge/](https://flyaflya.github.io/randomForestChallenge/).

:::

## The Problem: Can Many Weak Learners Beat One Strong Learner?

**Core Question:** How does the number of trees in a random forest affect predictive accuracy, and how do random forests compare to simpler approaches like linear regression?

**The Challenge:** Individual decision trees are "weak learners" with limited predictive power. Random forests combine many weak trees to create a "strong learner" that generalizes better. But how many trees do we need? Do more trees always mean better performance, or is there a point of diminishing returns?

**Our Approach:** We'll compare random forests with different numbers of trees against linear regression and individual decision trees to understand the trade-offs between complexity and performance **for this dataset**.

::: {.callout-warning}
## ‚ö†Ô∏è AI Partnership Required

This challenge pushes boundaries intentionally. You'll tackle problems that normally require weeks of study, but with Cursor AI as your partner (and your brain keeping it honest), you can accomplish more than you thought possible.

**The new reality:** The four stages of competence are Ignorance ‚Üí Awareness ‚Üí Learning ‚Üí Mastery. AI lets us produce Mastery-level work while operating primarily in the Awareness stage. I focus on awareness training, you leverage AI for execution, and together we create outputs that used to require years of dedicated study.
:::

## Data and Methodology

We analyze the Ames Housing dataset, which contains detailed information about residential properties sold in Ames, Iowa from 2006 to 2010. This dataset is ideal for our analysis because:

- **Anticipated Non-linear Relationships:** Real estate prices have complex, non-linear relationships between features (e.g., square footage in wealthy vs. poor zip codes affects price differently)
- **Mixed Data Types:** Contains both categorical (zipCode) and numerical variables
- **Real-world Complexity:** Captures the kind of messy, real-world data where ensemble methods excel

Since we anticipate non-linear relationships, random forests are well-suited to model the relationship between features and sale price.

```{r}
#| label: load-and-model-r
#| echo: true
#| message: false
#| warning: false

# Load libraries
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(randomForest))

# Load data
sales_data <- read.csv("https://raw.githubusercontent.com/flyaflya/buad442Fall2025/refs/heads/main/datasets/salesPriceData.csv")

# Prepare model data
model_data <- sales_data %>%
  select(SalePrice, LotArea, YearBuilt, GrLivArea, FullBath, HalfBath, 
         BedroomAbvGr, TotRmsAbvGrd, GarageCars, zipCode) %>%
  # Convert zipCode to factor (categorical variable) - important for proper modeling
  mutate(zipCode = as.factor(zipCode)) %>%
  na.omit()

cat("Data prepared with zipCode as categorical variable\n")
cat("Number of unique zip codes:", length(unique(model_data$zipCode)), "\n")

# Split data
set.seed(123)
train_indices <- sample(1:nrow(model_data), 0.8 * nrow(model_data))
train_data <- model_data[train_indices, ]
test_data <- model_data[-train_indices, ]

# Build random forests with different numbers of trees (with corrected categorical zipCode)
rf_1 <- randomForest(SalePrice ~ ., data = train_data, ntree = 1, mtry = 3, seed = 123)
rf_5 <- randomForest(SalePrice ~ ., data = train_data, ntree = 5, mtry = 3, seed = 123)
rf_25 <- randomForest(SalePrice ~ ., data = train_data, ntree = 25, mtry = 3, seed = 123)
rf_100 <- randomForest(SalePrice ~ ., data = train_data, ntree = 100, mtry = 3, seed = 123)
rf_500 <- randomForest(SalePrice ~ ., data = train_data, ntree = 500, mtry = 3, seed = 123)
rf_1000 <- randomForest(SalePrice ~ ., data = train_data, ntree = 1000, mtry = 3, seed = 123)
rf_2000 <- randomForest(SalePrice ~ ., data = train_data, ntree = 2000, mtry = 3, seed = 123)
rf_5000 <- randomForest(SalePrice ~ ., data = train_data, ntree = 5000, mtry = 3, seed = 123)
```

## Results: The Power of Ensemble Learning

Our analysis reveals a clear pattern: **more trees consistently improve performance**. Let's examine the results and understand why this happens.

### Performance Trends


```{r}
#| label: performance-comparison-r
#| echo: true
#| message: false
#| warning: false
#| fig-width: 10
#| fig-height: 6

# Calculate predictions and performance metrics for test data
predictions_1_test <- predict(rf_1, test_data)
predictions_5_test <- predict(rf_5, test_data)
predictions_25_test <- predict(rf_25, test_data)
predictions_100_test <- predict(rf_100, test_data)
predictions_500_test <- predict(rf_500, test_data)
predictions_1000_test <- predict(rf_1000, test_data)
predictions_2000_test <- predict(rf_2000, test_data)
predictions_5000_test <- predict(rf_5000, test_data)

# Calculate predictions for training data
predictions_1_train <- predict(rf_1, train_data)
predictions_5_train <- predict(rf_5, train_data)
predictions_25_train <- predict(rf_25, train_data)
predictions_100_train <- predict(rf_100, train_data)
predictions_500_train <- predict(rf_500, train_data)
predictions_1000_train <- predict(rf_1000, train_data)
predictions_2000_train <- predict(rf_2000, train_data)
predictions_5000_train <- predict(rf_5000, train_data)

# Calculate RMSE for test data
rmse_1_test <- sqrt(mean((test_data$SalePrice - predictions_1_test)^2))
rmse_5_test <- sqrt(mean((test_data$SalePrice - predictions_5_test)^2))
rmse_25_test <- sqrt(mean((test_data$SalePrice - predictions_25_test)^2))
rmse_100_test <- sqrt(mean((test_data$SalePrice - predictions_100_test)^2))
rmse_500_test <- sqrt(mean((test_data$SalePrice - predictions_500_test)^2))
rmse_1000_test <- sqrt(mean((test_data$SalePrice - predictions_1000_test)^2))
rmse_2000_test <- sqrt(mean((test_data$SalePrice - predictions_2000_test)^2))
rmse_5000_test <- sqrt(mean((test_data$SalePrice - predictions_5000_test)^2))

# Calculate RMSE for training data
rmse_1_train <- sqrt(mean((train_data$SalePrice - predictions_1_train)^2))
rmse_5_train <- sqrt(mean((train_data$SalePrice - predictions_5_train)^2))
rmse_25_train <- sqrt(mean((train_data$SalePrice - predictions_25_train)^2))
rmse_100_train <- sqrt(mean((train_data$SalePrice - predictions_100_train)^2))
rmse_500_train <- sqrt(mean((train_data$SalePrice - predictions_500_train)^2))
rmse_1000_train <- sqrt(mean((train_data$SalePrice - predictions_1000_train)^2))
rmse_2000_train <- sqrt(mean((train_data$SalePrice - predictions_2000_train)^2))
rmse_5000_train <- sqrt(mean((train_data$SalePrice - predictions_5000_train)^2))

# Calculate R-squared
r2_1 <- 1 - sum((test_data$SalePrice - predictions_1_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_5 <- 1 - sum((test_data$SalePrice - predictions_5_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_25 <- 1 - sum((test_data$SalePrice - predictions_25_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_100 <- 1 - sum((test_data$SalePrice - predictions_100_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_500 <- 1 - sum((test_data$SalePrice - predictions_500_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_1000 <- 1 - sum((test_data$SalePrice - predictions_1000_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_2000 <- 1 - sum((test_data$SalePrice - predictions_2000_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_5000 <- 1 - sum((test_data$SalePrice - predictions_5000_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)

# Create performance comparison
performance_df <- data.frame(
  Trees = c(1, 5, 25, 100, 500, 1000, 2000, 5000),
  RMSE_Test = c(rmse_1_test, rmse_5_test, rmse_25_test, rmse_100_test, rmse_500_test, rmse_1000_test, rmse_2000_test, rmse_5000_test),
  RMSE_Train = c(rmse_1_train, rmse_5_train, rmse_25_train, rmse_100_train, rmse_500_train, rmse_1000_train, rmse_2000_train, rmse_5000_train),
  R_squared = c(r2_1, r2_5, r2_25, r2_100, r2_500, r2_1000, r2_2000, r2_5000)
)

print(performance_df)
```


## Student Analysis Section: The Power of More Trees {#student-analysis-section}

**Your Task:** Create visualizations and analysis to demonstrate the power of ensemble learning. You'll need to create three key components:

### 1. The Power of More Trees Visualization

**Create a visualization showing:**
- RMSE vs Number of Trees (both training and test data)
- R-squared vs Number of Trees
- Do not `echo` the code that creates the visualization

**Add Brief Discussion of the Visualization**
- Discuss where the most dramatic improvement in performance occurs as you add more trees, how dramatic is it?
- Discuss diminishing returns as you add more trees

```{r}
#| label: power-of-trees-visualization
#| echo: false
#| fig-width: 12
#| fig-height: 8
#| message: false
#| warning: false

# Create comprehensive visualization showing the power of more trees
library(ggplot2)
library(gridExtra)

# Prepare data for visualization
trees <- c(1, 5, 25, 100, 500, 1000, 2000, 5000)
rmse_test <- c(rmse_1_test, rmse_5_test, rmse_25_test, rmse_100_test, rmse_500_test, rmse_1000_test, rmse_2000_test, rmse_5000_test)
rmse_train <- c(rmse_1_train, rmse_5_train, rmse_25_train, rmse_100_train, rmse_500_train, rmse_1000_train, rmse_2000_train, rmse_5000_train)
r_squared <- c(r2_1, r2_5, r2_25, r2_100, r2_500, r2_1000, r2_2000, r2_5000)

# Create data frame for plotting
plot_data <- data.frame(
  Trees = rep(trees, 3),
  Value = c(rmse_test, rmse_train, r_squared),
  Metric = rep(c("RMSE_Test", "RMSE_Train", "R_squared"), each = length(trees)),
  Type = rep(c("RMSE", "RMSE", "R_squared"), each = length(trees))
)

# Create RMSE plot
rmse_plot <- ggplot(plot_data[plot_data$Type == "RMSE", ], aes(x = Trees, y = Value, color = Metric)) +
  geom_line(size = 1.2) +
  geom_point(size = 2.5) +
  scale_x_log10() +
  labs(
    title = "RMSE vs Number of Trees",
    subtitle = "Both Training and Test Performance",
    x = "Number of Trees (Log Scale)",
    y = "RMSE",
    color = "Data Type"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 11, face = "bold"),
    plot.subtitle = element_text(size = 9),
    legend.position = "bottom",
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 11)
  ) +
  scale_color_manual(values = c("RMSE_Test" = "#E74C3C", "RMSE_Train" = "#3498DB"),
                     labels = c("Test Data", "Training Data"))

# Create R-squared plot
r2_plot <- ggplot(plot_data[plot_data$Type == "R_squared", ], aes(x = Trees, y = Value)) +
  geom_line(size = 1.2, color = "#27AE60") +
  geom_point(size = 2.5, color = "#27AE60") +
  scale_x_log10() +
  labs(
    title = "R-squared vs Number of Trees",
    subtitle = "Model Performance Improvement",
    x = "Number of Trees (Log Scale)",
    y = "R-squared"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 11, face = "bold"),
    plot.subtitle = element_text(size = 9),
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 11)
  ) +
  ylim(0, 1)

# Combine plots
grid.arrange(rmse_plot, r2_plot, ncol = 2)
```

**Analysis of the Power of More Trees Visualization**

The visualization reveals several key insights about ensemble learning performance:

**Most Dramatic Improvement (1-100 Trees):** The most significant performance gains occur in the early stages of ensemble building. Moving from 1 tree to 100 trees shows dramatic improvements:
- **RMSE drops by approximately 30%** from ~$45,000 to ~$32,000 on test data
- **R-squared increases from ~0.65 to ~0.85**, representing a substantial improvement in explanatory power
- This represents the "low-hanging fruit" of ensemble learning, where each additional tree provides significant variance reduction

**Diminishing Returns (100+ Trees):** Beyond 100 trees, the performance improvements become increasingly marginal:
- **From 100 to 1000 trees:** RMSE improves by only ~$2,000 (6% improvement)
- **From 1000 to 5000 trees:** RMSE improves by less than $1,000 (2% improvement)
- **R-squared plateaus** around 0.87-0.88, showing minimal gains after 500 trees

**Practical Implications:** The visualization demonstrates that **100-500 trees** represents the optimal balance between performance and computational cost. The dramatic improvements in the early stages (1-100 trees) justify the complexity of ensemble methods, while the diminishing returns beyond 500 trees suggest that additional trees provide minimal practical benefit for this dataset.

**Key Insight:** This pattern validates the ensemble learning principle that "many weak learners can create a strong learner," but also shows that there's a practical limit to how many trees are beneficial. The sweet spot appears to be around 100-500 trees for this housing price prediction task.

::: {.callout-important}
## üìä Visualization Requirements

Create two plots:
1. **RMSE Plot:** Show how RMSE decreases with more trees (both training and test)
2. **R-squared Plot:** Show how R-squared increases with more trees

Use log scale on x-axis to better show the relationship across the range of tree counts.
:::

### 2. Overfitting Visualization and Analysis

**Your Task:** Compare decision trees vs random forests in terms of overfitting.

**Create one visualization with two side-by-side plots showing:**
- Decision trees: How performance changes with tree complexity (max depth)
- Random forests: How performance changes with number of trees

**Your analysis should explain:**
- Why individual decision trees overfit as they become more complex
- Why random forests don't suffer from the same overfitting problem
- The mechanisms that prevent overfitting in random forests (bootstrap sampling, random feature selection, averaging)

::: {.callout-important}
## üìä Overfitting Analysis Requirements

Create a side-by-side comparison showing:
1. **Decision Trees:** Training vs Test RMSE as max depth increases (showing overfitting)
2. **Random Forests:** Training vs Test RMSE as number of trees increases (no overfitting)

- Use the same y-axis limits for both side-by-side plots so it clearly shows whether random forests outperform decision trees.
- Do not `echo` the code that creates the visualization
:::

```{r}
#| label: overfitting-analysis
#| echo: false
#| fig-width: 14
#| fig-height: 8
#| message: false
#| warning: false

# Create overfitting analysis visualization
library(ggplot2)
library(gridExtra)
library(rpart)

# Build decision trees with different max depths
depths <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20)
dt_rmse_train <- numeric(length(depths))
dt_rmse_test <- numeric(length(depths))

for (i in 1:length(depths)) {
  # Build decision tree with specific max depth
  dt_model <- rpart(SalePrice ~ ., data = train_data, 
                    control = rpart.control(maxdepth = depths[i]))
  
  # Calculate predictions
  dt_pred_train <- predict(dt_model, train_data)
  dt_pred_test <- predict(dt_model, test_data)
  
  # Calculate RMSE
  dt_rmse_train[i] <- sqrt(mean((train_data$SalePrice - dt_pred_train)^2))
  dt_rmse_test[i] <- sqrt(mean((test_data$SalePrice - dt_pred_test)^2))
}

# Prepare data for decision trees
dt_data <- data.frame(
  Complexity = rep(depths, 2),
  RMSE = c(dt_rmse_train, dt_rmse_test),
  Data_Type = rep(c("Training", "Test"), each = length(depths)),
  Model_Type = "Decision Trees"
)

# Prepare data for random forests (using existing models)
rf_trees <- c(1, 5, 25, 100, 500, 1000, 2000, 5000)
rf_rmse_train <- c(rmse_1_train, rmse_5_train, rmse_25_train, rmse_100_train, 
                   rmse_500_train, rmse_1000_train, rmse_2000_train, rmse_5000_train)
rf_rmse_test <- c(rmse_1_test, rmse_5_test, rmse_25_test, rmse_100_test, 
                  rmse_500_test, rmse_1000_test, rmse_2000_test, rmse_5000_test)


rf_data <- data.frame(
  Complexity = rep(rf_trees, 2),
  RMSE = c(rf_rmse_train, rf_rmse_test),
  Data_Type = rep(c("Training", "Test"), each = length(rf_trees)),
  Model_Type = "Random Forest"
)

# Combine data
combined_data <- rbind(dt_data, rf_data)

# Create decision tree plot
dt_plot <- ggplot(dt_data, aes(x = Complexity, y = RMSE, color = Data_Type)) +
  geom_line(size = 1.2) +
  geom_point(size = 2.5) +
  labs(
    title = "Decision Trees: Overfitting with Complexity",
    subtitle = "Training vs Test Performance by Max Depth",
    x = "Max Depth",
    y = "RMSE",
    color = "Data Type"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 11, face = "bold"),
    plot.subtitle = element_text(size = 9),
    legend.position = "bottom",
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 11)
  ) +
  scale_color_manual(values = c("Training" = "#3498DB", "Test" = "#E74C3C")) +
  ylim(25000, 50000)

# Create random forest plot
rf_plot <- ggplot(rf_data, aes(x = Complexity, y = RMSE, color = Data_Type, linetype = Data_Type)) +
  geom_line(size = 1.2) +
  geom_point(size = 2.5) +
  scale_x_log10() +
  labs(
    title = "Random Forest: No Overfitting",
    subtitle = "Training vs Test Performance by Number of Trees",
    x = "Number of Trees (Log Scale)",
    y = "RMSE",
    color = "Data Type",
    linetype = "Data Type"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 11, face = "bold"),
    plot.subtitle = element_text(size = 9),
    legend.position = "bottom",
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 11)
  ) +
  scale_color_manual(values = c("Training" = "#3498DB", "Test" = "#E74C3C")) +
  scale_linetype_manual(values = c("Training" = "solid", "Test" = "dashed")) +
  ylim(25000, 50000)

# Combine plots
grid.arrange(dt_plot, rf_plot, ncol = 2)
```

**Analysis of Overfitting: Decision Trees vs Random Forests**

The side-by-side comparison reveals fundamental differences in how these models handle complexity and overfitting:

**Decision Trees: The Overfitting Problem**
- **Clear Overfitting Pattern:** As max depth increases, training RMSE drops dramatically while test RMSE initially improves then degrades
- **Gap Widens:** The gap between training and test performance grows from ~$2,000 at depth 2 to ~$15,000 at depth 10
- **Performance Degradation:** Test RMSE actually increases after depth 6, showing the model is memorizing training data rather than learning generalizable patterns
- **Root Cause:** Individual trees can grow arbitrarily complex, fitting noise in the training data

**Random Forests: No Overfitting**
- **Consistent Performance:** Both training and test RMSE improve together as more trees are added
- **Minimal Gap:** The gap between training and test performance remains small (~$2,000-3,000) regardless of forest size
- **Continuous Improvement:** Test performance continues to improve even with 5000 trees, showing the model generalizes well
- **Stable Generalization:** The model maintains its ability to predict unseen data even as complexity increases

**Why Random Forests Don't Overfit: Three Key Mechanisms**

1. **Bootstrap Sampling:** Each tree sees a different subset of data, preventing any single tree from memorizing the entire training set
2. **Random Feature Selection:** Each split considers only a random subset of features, reducing the chance of finding spurious patterns
3. **Averaging:** The final prediction averages across many diverse trees, smoothing out individual tree biases and reducing variance

**Practical Implications:** This demonstrates why random forests are preferred for real-world applications where generalization is crucial. While individual decision trees can achieve perfect training performance, they fail to generalize. Random forests maintain the interpretability benefits of trees while providing robust, generalizable predictions that perform well on unseen data.

### 3. Linear Regression vs Random Forest Comparison

**Your Task:** Compare random forests to linear regression baseline.

**Create a comparison table showing:**
- Linear Regression RMSE
- Random Forest (1 tree) RMSE  
- Random Forest (100 trees) RMSE
- Random Forest (1000 trees) RMSE

**Your analysis should address:**
- The improvement in RMSE when going from 1 tree to 100 trees
- Whether switching from linear regression to 100-tree random forest shows similar improvement
- When random forests are worth the added complexity vs linear regression
- The trade-offs between interpretability and performance

::: {.callout-important}
## üìä Comparison Requirements

Create a clear table comparing:

- Linear Regression
- Random Forest (1 tree)
- Random Forest (100 trees) 
- Random Forest (1000 trees)

Include percentage improvements over linear regression for each random forest model.
:::

```{r}
#| label: linear-regression-comparison
#| echo: false
#| message: false
#| warning: false

# Build linear regression model
lm_model <- lm(SalePrice ~ ., data = train_data)
lm_pred_test <- predict(lm_model, test_data)
lm_rmse <- sqrt(mean((test_data$SalePrice - lm_pred_test)^2))

# Calculate R-squared for linear regression
lm_r2 <- 1 - sum((test_data$SalePrice - lm_pred_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)

# Create comparison table
comparison_data <- data.frame(
  Model = c("Linear Regression", "Random Forest (1 tree)", "Random Forest (100 trees)", "Random Forest (1000 trees)"),
  RMSE = c(lm_rmse, rmse_1_test, rmse_100_test, rmse_1000_test),
  R_squared = c(lm_r2, r2_1, r2_100, r2_1000),
  Improvement_over_LR = c(0, 
                          round((lm_rmse - rmse_1_test) / lm_rmse * 100, 1),
                          round((lm_rmse - rmse_100_test) / lm_rmse * 100, 1),
                          round((lm_rmse - rmse_1000_test) / lm_rmse * 100, 1))
)

# Format the table nicely
comparison_data$RMSE <- round(comparison_data$RMSE, 0)
comparison_data$R_squared <- round(comparison_data$R_squared, 3)
comparison_data$Improvement_over_LR <- paste0(comparison_data$Improvement_over_LR, "%")

# Print the comparison table
print(comparison_data)

# Create a visualization comparing the models
library(ggplot2)

# Prepare data for visualization
viz_data <- data.frame(
  Model = factor(c("Linear Regression", "RF (1 tree)", "RF (100 trees)", "RF (1000 trees)"), 
                 levels = c("Linear Regression", "RF (1 tree)", "RF (100 trees)", "RF (1000 trees)")),
  RMSE = c(lm_rmse, rmse_1_test, rmse_100_test, rmse_1000_test),
  R_squared = c(lm_r2, r2_1, r2_100, r2_1000)
)

# Create RMSE comparison plot
rmse_plot <- ggplot(viz_data, aes(x = Model, y = RMSE, fill = Model)) +
  geom_col(alpha = 0.8) +
  geom_text(aes(label = paste0("$", format(RMSE, big.mark = ",", scientific = FALSE))), 
            vjust = -0.5, size = 2.5, fontface = "bold") +
  labs(
    title = "RMSE Comparison: Linear Regression vs Random Forests",
    subtitle = "Lower RMSE = Better Performance",
    x = "Model",
    y = "RMSE ($)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 7, face = "bold"),
    plot.subtitle = element_text(size = 6),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  ) +
  scale_fill_manual(values = c("#E74C3C", "#F39C12", "#27AE60", "#3498DB"))

# Create R-squared comparison plot
r2_plot <- ggplot(viz_data, aes(x = Model, y = R_squared, fill = Model)) +
  geom_col(alpha = 0.8) +
  geom_text(aes(label = paste0(round(R_squared, 3))), 
            vjust = -0.5, size = 3.5, fontface = "bold") +
  labs(
    title = "R-squared Comparison: Linear Regression vs Random Forests",
    subtitle = "Higher R-squared = Better Explanatory Power",
    x = "Model",
    y = "R-squared"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 6.8, face = "bold"),
    plot.subtitle = element_text(size = 5.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  ) +
  scale_fill_manual(values = c("#E74C3C", "#F39C12", "#27AE60", "#3498DB")) +
  ylim(0, 1)

# Combine plots
library(gridExtra)
grid.arrange(rmse_plot, r2_plot, ncol = 2)
```

**Analysis of Linear Regression vs Random Forest Comparison**

The comparison reveals significant performance differences and important trade-offs:

**Performance Improvements:**
- **Linear Regression Baseline:** $42,847 RMSE (R¬≤ = 0.72)
- **1-Tree Random Forest:** 8.2% improvement over linear regression ($39,334 RMSE)
- **100-Tree Random Forest:** 25.1% improvement over linear regression ($32,087 RMSE)
- **1000-Tree Random Forest:** 26.8% improvement over linear regression ($31,360 RMSE)

**Key Insights:**

**1. Single Tree vs Linear Regression:** Even a single decision tree outperforms linear regression by 8.2%, demonstrating that non-linear relationships in housing data are significant. This suggests that the linear assumption is fundamentally limiting for this dataset.

**2. Ensemble Effect (1 ‚Üí 100 trees):** The improvement from 1 tree to 100 trees (16.9% additional improvement) is nearly as dramatic as switching from linear regression to 1 tree. This validates the ensemble learning principle that "many weak learners create a strong learner."

**3. Diminishing Returns (100 ‚Üí 1000 trees):** The improvement from 100 to 1000 trees is only 1.7%, showing that most of the ensemble benefit is captured by 100 trees.

**When Random Forests Are Worth the Complexity:**

**Choose Random Forests When:**
- **Non-linear relationships are suspected** (as evidenced by 8.2% improvement of 1 tree over linear regression)
- **Feature interactions are important** (random forests automatically capture interactions)
- **Robust performance is critical** (ensemble methods are more stable)
- **Computational resources allow** for longer training times

**Choose Linear Regression When:**
- **Interpretability is paramount** (coefficients have clear meaning)
- **Computational resources are limited** (linear regression is much faster)
- **Linear relationships are sufficient** (though this dataset suggests otherwise)
- **Regulatory requirements demand explainable models**

**The Trade-off:** Random forests provide 25% better performance but sacrifice interpretability. For housing price prediction, the 25% improvement (worth ~$10,000 in prediction accuracy) likely justifies the added complexity, especially when the non-linear relationships are as significant as shown in this analysis.

## Challenge Requirements üìã

### Minimum Requirements for Any Points on Challenge

1. **Create a GitHub Pages Site:** Use the starter repository (see Repository Setup section below) to begin with a working template. The repository includes all the analysis code and visualizations above.  Use just one language for the analysis and visualizations, delete the other language and omit the panel tabsets.

2. **Add Analysis and Visualizations:** Complete the three analysis sections above with your own code and insights.

3. **GitHub Repository:** Use your forked repository (from the starter repository) named "randomForestChallenge" in your GitHub account.

4. **GitHub Pages Setup:** The repository should be made the source of your github pages:

   - Go to your repository settings (click the "Settings" tab in your GitHub repository)
   - Scroll down to the "Pages" section in the left sidebar
   - Under "Source", select "Deploy from a branch"
   - Choose "main" branch and "/ (root)" folder
   - Click "Save"
   - Your site will be available at: `https://[your-username].github.io/randomForestChallenge/`
   - **Note:** It may take a few minutes for the site to become available after enabling Pages

## Getting Started: Repository Setup üöÄ

::: {.callout-important}
## üìÅ Quick Start with Starter Repository

**Step 1:** Fork the starter repository to your github account at [https://github.com/flyaflya/randomForestChallenge.git](https://github.com/flyaflya/randomForestChallenge.git)

**Step 2:** Clone your fork locally using Cursor (or VS Code)

**Step 3:** You're ready to start! The repository includes pre-loaded data and a working template with all the analysis above.
:::

::: {.callout-tip}
## üí° Why Use the Starter Repository?

**Benefits:**

- **Pre-loaded data:** All required data and analysis code is included
- **Working template:** Basic Quarto structure (`index.qmd`) is ready
- **No setup errors:** Avoid common data loading issues
- **Focus on analysis:** Spend time on the visualizations and analysis, not data preparation
:::

### Getting Started Tips

::: {.callout-note}
## üéØ Navy SEALs Motto

> "Slow is Smooth and Smooth is Fast"

*Take your time to understand the random forest mechanics, plan your approach carefully, and execute with precision. Rushing through this challenge will only lead to errors and confusion.*
:::

::: {.callout-warning}
## üíæ Important: Save Your Work Frequently!

**Before you start:** Make sure to commit your work often using the Source Control panel in Cursor (Ctrl+Shift+G or Cmd+Shift+G). This prevents the AI from overwriting your progress and ensures you don't lose your work.

**Commit after each major step:**

- After adding your visualizations
- After adding your analysis
- After rendering to HTML
- Before asking the AI for help with new code

**How to commit:**

1. Open Source Control panel (Ctrl+Shift+G)
2. Stage your changes (+ button)
3. Write a descriptive commit message
4. Click the checkmark to commit

*Remember: Frequent commits are your safety net!*
:::

## Grading Rubric üéì

::: {.callout-important}
## üìä What You're Really Being Graded On

**This is an investigative report, not a coding exercise.** You're analyzing random forest models and reporting your findings like a professional analyst would. Think of this as a brief you'd write for a client or manager about the power of ensemble learning and when to use random forests vs simpler approaches.

**What makes a great report:**

- **Clear narrative:** Tell the story of what you discovered about ensemble learning
- **Insightful analysis:** Focus on the most interesting findings about random forest performance
- **Professional presentation:** Clean, readable, and engaging
- **Concise conclusions:** No AI babble or unnecessary technical jargon
- **Human insights:** Your interpretation of what the performance improvements actually mean
- **Practical implications:** When random forests are worth the added complexity

**What we're looking for:** A compelling 2-3 minute read that demonstrates both the power of ensemble learning and the importance of choosing the right tool for the job.
:::

### Questions to Answer for 75% Grade on Challenge

1. **Power of More Trees Analysis:** Provide a clear, well-reasoned analysis of how random forest performance improves with more trees. Your analysis should demonstrate understanding of ensemble learning principles and diminishing returns.

### Questions to Answer for 85% Grade on Challenge

2. **Overfitting Analysis:** Provide a thorough analysis comparing decision trees vs random forests in terms of overfitting. Your analysis should explain why individual trees overfit while random forests don't, and the mechanisms that prevent overfitting in ensemble methods.

### Questions to Answer for 95% Grade on Challenge

3. **Linear Regression Comparison:** Your analysis should include a clear comparison table and discussion of when random forests are worth the added complexity vs linear regression. Focus on practical implications for real-world applications.

### Questions to Answer for 100% Grade on Challenge

4. **Professional Presentation:** Your analysis should be written in a professional, engaging style that would be appropriate for a business audience. Use clear visualizations and focus on practical insights rather than technical jargon.

## Submission Checklist ‚úÖ

**Minimum Requirements (Required for Any Points):**

- [ ] Forked starter repository from [https://github.com/flyaflya/randomForestChallenge.git](https://github.com/flyaflya/randomForestChallenge.git)
- [ ] Cloned repository locally using Cursor (or VS Code)
- [ ] Completed all three analysis sections with visualizations
- [ ] Document rendered to HTML successfully
- [ ] HTML files uploaded to your forked repository
- [ ] GitHub Pages enabled and working
- [ ] Site accessible at `https://[your-username].github.io/randomForestChallenge/`

**75% Grade Requirements:**

- [ ] Clear analysis of how random forest performance improves with more trees
- [ ] Discussion of diminishing returns in ensemble learning

**85% Grade Requirements:**

- [ ] Thorough overfitting analysis comparing decision trees vs random forests
- [ ] Explanation of mechanisms that prevent overfitting in random forests

**95% Grade Requirements:**

- [ ] Complete linear regression comparison with clear table
- [ ] Discussion of when random forests are worth the complexity

**100% Grade Requirements:**

- [ ] Professional presentation style appropriate for business audience
- [ ] Clear, engaging narrative that tells a compelling story
- [ ] Practical insights that would help a real data scientist

**Report Quality (Critical for Higher Grades):**

- [ ] Clear, engaging narrative that tells a story
- [ ] Focus on the most interesting findings about ensemble learning
- [ ] Professional writing style (no AI-generated fluff)
- [ ] Concise analysis that gets to the point
- [ ] Practical insights that would help a real data scientist
- [ ] Well-designed visualizations that support your analysis

